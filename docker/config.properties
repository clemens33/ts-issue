# docker relevant settings
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
number_of_netty_threads=32
job_queue_size=1000

# necessary to download py requirements
install_py_dep_per_model=true
default_workers_per_model=1

# allow application/json requests
service_envelope=body

# necessary due to initial download of large pre-trained models during worker startup
default_response_timeout=600000

# for custom log4j settings
vmargs=-Dlog4j.configuration=log4j.properties

# model store location
model-store=/home/model-server/model_store

model_snapshot={"name":"startup.cfg","modelCount":1,"models":{"dummy":{"0.1":{"defaultVersion":true,"marName":"dummy_nomodel.mar","minWorkers":3,"maxWorkers":3,"batchSize":256,"maxBatchDelay":100,"responseTimeout":600}}}}
